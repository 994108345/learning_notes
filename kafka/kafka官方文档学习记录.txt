kafka主要的三个功能
	1 订阅和发布记录流，类似于企业消息系统。
	2 用一个容错的持久化方式保存记录流。
	3 处理发生的记录流。
	
kafka使用的两个主要场景
	构建实时流数据管道，可靠地获取系统或应用程序之间的数据
	构建转换或响应数据流的实时流应用程序
	
kafka的一些概念
	kafka是作为一个集群运行在一个或多个可以跨服务中心的服务上。
	Kafka集群将记录流存储在称为主题的类别中。
	每个记录由一个键、一个值和一个时间戳组成。
	
kafka有四个核心的api
	Producer API
		允许一个应用去给一个或多个主题发布一个记录流
	Consumer API
		允许一个应用去监听一个或多个主题并处理提供给他们的记录流
	Stream API
		允许一个应用成为流的管理者，从一个或多个主题消费一个输入流，给一个或多个输出主题提供一个输出流。有效是将一个输入流转换成一个输出流
	Connector API
		Connector API允许构建和运行将Kafka主题连接到现有应用程序或数据系统的可重用生产者或消费者。例如，连接到关系数据库的连接器可能捕获对表的每个更改。
		
在Kafka中，客户机和服务器之间的通信是通过一个简单的、高性能的、与语言无关的TCP协议完成的。此协议经过版本控制，并与旧版本保持向后兼容性。我们为Kafka提供了一个Java客户机，但是客户机可以使用多种语言。

kafka中几个比较重要的对象概念

	broker：代理，
		标识集群服务的节点，用broker_id来区别，多个broker 就组成了kafka集群。
		
	topic：主题：
		是数据记录发布的地方。topic当中以日志信息的形式存贮着消息。从old到new，以offset偏移量来记录消息的先后关系。
		
	partition:分区
		对于每一个topic，都会至少维持一个分区。分区里存储着topic的日志信息。一个主题可能有一个或多个分区，多个分区分别分布在不同的broker上，且数据是一样的。多个分区之间有主从关系。一般有一个leader和多个follower，leader处理一切对partition的读写请求，follower只负责将leader分区的数据同步过来。一旦leader宕机，会从剩下的folloer分区中选举出一个leader，增加了容错性。
		kafka只保证每个分区内的数据是有序的，但是不能保证不同分区中的数据是有序的。
		
	备份
		每一个分区里的数据又叫做备份。
		
	consumer:服务消费者
		消费者自己带着元数据offset偏移量去消费topic中分区的数据，所以数据的访问控制在消费者这边。
		kafka的消费者一般由多个消费者实例组成一个消费组，每个消费组对应自己的topic。当一个消费组消费一个topic时，消费组中的不同消费实例会均衡负载的消费topic里的日志信息，不同的消费组消费同一个topic，topic会广播给每一个消费组。
		均衡负载：一个消费组，消费了topic 10条消息，消费组里的每个消费实例消费信息数量的总和是10.
		广播：多个消费组，各消费了topic 10条消息。
		
	producer:服务提供者
		服务提供者负责将数据存到对应topic 的分区中
	
	
kafka的保证
	1 每个分区会按照消息提供者发送的顺序存放数据
	2 消费者会按照分区的日志顺序去消费信息
	3 具有n个副本的kafka最多只允许n-1个服务器故障，从而保证数据不丢失任何提交到服务的日志。
	
kafka和传统的消息系统的对比
	消息的消费方式
		传统的消息系统主要分为队列和发布/订阅两种。通常队列的消息被消费后就要立马被移除。发布的消息会广播给所有的订阅者。
		kafka有效的避免的上述的两种问题。kafka的数据一直存在磁盘中，就算被消费了也不会被删除，只是cousumer的offset偏移量有了改变。kafka的topic中的消息只会广播给指定的消费组，其他没有关联的消费组不会被广播。
	消费的顺序性
		传统的消息系统，多个消费者消费同一个队列的时候，因为是通过异步实现的，无法保证消费者消费到的消息是有序的，一般只能通过一个消费者去消费来保证顺序的正确性。
		kafka通过要求消费组的每一个消费实例去匹配一个分区，来保证消费到的消息是有序的，要求消费组中的消费者实例数不能大于分区数。
		
kafka作为存储系统
	数据写入到kafka和写入磁盘，并且进行备份防止容错。直到备份完毕，kafka才会告诉provider消息完成写入，即使写入失败，kafka也会确保持久化到磁盘。
	kafka使用的磁盘结构，具有很好的扩展性。所以磁盘的大小并不影响kafka的性能。
	kafka可以存储大量数据，并且可以在客户端控制他读取的记录位置，您可认为Kafka是一种高性能、低延迟、具备日志存储、备份和传播功能的分布式文件系统。
	
kafka用作流处理
	面对复杂的数据变换。通过简单的provider和consumer API已经不能解决。Kafka提供了stream Api做一些复杂操作。比如讲流数据聚合或者join。具体后面研究
	
kafka批处理
	


	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	